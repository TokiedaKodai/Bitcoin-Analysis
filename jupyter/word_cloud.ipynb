{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import json\n",
    "from janome.tokenizer import Tokenizer\n",
    "from requests_oauthlib import OAuth1Session\n",
    "from wordcloud import WordCloud\n",
    "import emoji\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_oauth_session(oauth_key_dict):\n",
    "    oauth = OAuth1Session(\n",
    "        oauth_key_dict['consumer_key'],\n",
    "        oauth_key_dict['consumer_secret'],\n",
    "        oauth_key_dict['access_token'],\n",
    "        oauth_key_dict['access_token_secret']\n",
    "    )\n",
    "    return oauth\n",
    "\n",
    "def tweet(oauth, text):\n",
    "    url = 'https://api.twitter.com/1.1/statuses/update.json'\n",
    "    params = {'status': text + '\\n#TweetFromPy'}\n",
    "    req = oauth.post(url, params)\n",
    "\n",
    "    if req.status_code == 200:\n",
    "        print('tweet succeed!')\n",
    "    else:\n",
    "        print('tweet failed')\n",
    "        \n",
    "def tweet_image(oauth, text, image_file):\n",
    "    url_media = \"https://upload.twitter.com/1.1/media/upload.json\"\n",
    "    url_text = \"https://api.twitter.com/1.1/statuses/update.json\"\n",
    "    \n",
    "    files = {\"media\" : open(image_file, 'rb')}\n",
    "    req_media = oauth.post(url_media, files = files)\n",
    "    if req_media.status_code != 200:\n",
    "        print ('media upload failed: %s', req_media.text)\n",
    "        exit()\n",
    "        \n",
    "    media_id = json.loads(req_media.text)['media_id']\n",
    "    print (\"Media ID: %d\" % media_id)\n",
    "    \n",
    "    params = {'status': text + '\\n#TweetFromPy', 'media_ids': [media_id]}\n",
    "    req = oauth.post(url_text, params)\n",
    "\n",
    "    if req.status_code == 200:\n",
    "        print('tweet succeed!')\n",
    "    else:\n",
    "        print('tweet failed')\n",
    "        \n",
    "def tweet_search(search_word, num, oauth):\n",
    "    url = 'https://api.twitter.com/1.1/search/tweets.json'\n",
    "    params = {\n",
    "        'q': search_word,\n",
    "        'count' : num,\n",
    "        'result_type' : 'recent',\n",
    "        'exclude': 'retweets',\n",
    "        'lang' : 'ja'\n",
    "        }\n",
    "    responce = oauth.get(url, params=params)\n",
    "    if responce.status_code != 200:\n",
    "        print(\"Error code: %d\" %(responce.status_code))\n",
    "        return None\n",
    "    tweets = json.loads(responce.text)\n",
    "    return tweets\n",
    "\n",
    "keysfile = '../../twitter_API/key/keys.json'\n",
    "keys = json.load(open(keysfile))\n",
    "oauth = create_oauth_session(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(text):\n",
    "    return ''.join(c for c in text if c not in emoji.UNICODE_EMOJI['en'])\n",
    "\n",
    "def remove_url(text):\n",
    "    return re.sub(r'https?://[\\w/:%#\\$&\\?\\(\\)~\\.=\\+\\-]+', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = tweet_search(\"ãƒ“ãƒƒãƒˆã‚³ã‚¤ãƒ³\", 100, oauth)\n",
    "df_search = DataFrame.from_dict(search['statuses'])\n",
    "tweets = df_search['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['å¹´å†…ã«3å€ä»¥ä¸Šï¼ŸğŸ‘€ğŸ”¥ãƒ“ãƒƒãƒˆã‚³ã‚¤ãƒ³ã‚‚ã‚¤ãƒ¼ã‚µãƒªã‚¢ãƒ ã‚‚æ€¥é¨°ä¸­ï¼XRPæœ€æ–°æƒ…å ±ï¼†ç†±ã„ã‚ªãƒ«ãƒˆã‚³ã‚¤ãƒ³Chainlinkã¨FrontierãŒææºï¼Dogeã‚³ã‚¤ãƒ³ã®è¬ã®æ€¥æˆé•·ã¨NFTæœ€æ–°æƒ…å ±ï¼ï¼ˆå‹•ç”»ï¼‰â€¦ https://t.co/JFLLfQ37Ax',\n",
       " 'ã‚¤ãƒ¼ã‚µãƒªã‚¢ãƒ ãŒãƒˆãƒ¬ãƒ³ãƒ‰å…¥ã‚Šã—ã¦ã‚‹ã€‚\\nå¹´æœ«ã®ãƒ“ãƒƒãƒˆã‚³ã‚¤ãƒ³ã®ä¼¸ã³ã‚’é‘‘ã¿ã‚‹ã¨ã€3,400ãƒ‰ãƒ«ãŒã„ã£ãŸã‚“ã®ç¯€ç›®ã ã¨æ€ã£ã¦ã‚‹ã€‚\\n\\n#100ä¸‡è¡Œãã¾ã§å£²ã‚Šã¾ã›ã‚“\\n#ETH #ã‚¤ãƒ¼ã‚µãƒªã‚¢ãƒ ',\n",
       " 'ãƒ“ãƒƒãƒˆã‚³ã‚¤ãƒ³ã€è²·ã„ãŸã„æ°—æŒã¡ã€ç„¦ã‚‹æ°—æŒã¡ãŒå€¤æ®µãŒä¸ŠãŒã‚‹ã«ã¤ã‚Œã¦å‡ºã¦ãã‚‹ã‘ã©ã€æˆ‘æ…¢ãŒå¤§äº‹ã§ã™ã‚ˆã­',\n",
       " 'BAT ãƒ™ãƒ¼ã‚·ãƒƒã‚¯ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒˆãƒ¼ã‚¯ãƒ³ã¯\\nPoL @PoL_techtec ã®ã‚µã‚¤ãƒˆã§å­¦ã¹ã¾ã™ï¼\\n\\nä»®æƒ³é€šè²¨ã¯å€¤å‹•ãã®ä¸Šä¸‹ã ã‘ã§ã¯ãªãã€\\nä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹æŠ€è¡“ã«ã¤ã„ã¦è¦‹è­˜ã‚’æ·±ã‚ã‚‹ã®ã‚‚ã‚ˆãã§ã™ã­ï¼\\n\\nãƒ“ãƒƒãƒˆã‚³ã‚¤ãƒ³ ã‚„ ã‚¤ãƒ¼ã‚µãƒªã‚¢ãƒ ã‚‚Pâ€¦ https://t.co/dsY7F5o1RG',\n",
       " '@UNOu3JaOmk4Tt9i ãƒ“ãƒƒãƒˆã‚³ã‚¤ãƒ³ğŸ˜ï¼Ÿ',\n",
       " 'ãƒ“ãƒƒãƒˆã‚³ã‚¤ãƒ³ã®æœ€å¾Œã®åŠæ¸›æœŸå¾Œã£ã¦ã©ã†ãªã‚‹ã‚“ã§ã™ã‹ï¼Ÿ',\n",
       " 'ãƒ“ãƒƒãƒˆã‚³ã‚¤ãƒ³ã¾ãŸã‚ã¡ã‚ƒãã¡ã‚ƒå·»ãè¿”ã—ã¦ã‚‹ã­ã€‚1ä¸‡å††åˆ†ã ã‘ã—ã‹ãªã„ã‘ã©ã€ã›ã£ã‹ãã ã‹ã‚‰ä½•ãŒã‚ã£ã¦ã‚‚ç½®ã„ã¦ãŠã“ã†ã‹ãªâ€¦ã€‚',\n",
       " '@fuyuto_topics ã‚¦ã‚©ãƒ¬ãƒƒãƒˆã‚’å§‹ã‚ãŸé ƒãƒ“ãƒƒãƒˆã‚³ã‚¤ãƒ³ãŒã‚‚ã†é«˜ã‚ã ã£ãŸã®ã§ä½ã„ã‚¤ãƒ¼ã‚µãƒ ã«çµã‚Šã¾ã—ãŸã€‚\\nã“ã‚Œã‹ã‚‰ã‚‚ãƒã‚¤ãƒ³ãƒˆã¯ä¸‹ãŒã‚Œã°ãƒ“ãƒƒãƒˆã‚³ã‚¤ãƒ³ã¨ã‚¤ãƒ¼ã‚µãƒ ã‚’è²·ã„ç¶šã‘ã¾ã™ã€‚',\n",
       " 'ãƒ“ãƒƒãƒˆã‚³ã‚¤ãƒ³è²·ã£ã¦ã‚‹äººï¼\\nã©ã“ã®ã‚µã‚¤ãƒˆã§è²·ã£ã¦ã‚‹ï¼Ÿï¼Ÿ',\n",
       " 'çŸ­æœŸãƒˆãƒ¬ãƒ¼ãƒ‰ã®ã‚¤ãƒ¡ãƒ¼ã‚¸\\n\\næ±å¤§ã«è¡Œã‘ã‚‹äººãŒã„ã‚‹ã‚ˆã†ã«ã€å¯èƒ½æ€§ã¯å¦å®šã§ããªã„ã—\\nTwitterã«ã¯ãã‚Œä»¥ä¸Šã®è¶…äººãŒã„ã£ã±ã„ã‚‹ã€‚ãƒ“ãƒƒãƒˆã‚³ã‚¤ãƒ³ã¿ãŸã„ãªå¯èƒ½æ€§ã‚‚ã‚ã‚‹ã‚ã‘ã ã—ãªã€‚äººç”Ÿè‰¯ãã‚‚æ‚ªãã‚‚ä½•ãŒã‚ã‚‹ã‹åˆ†ã‹ã‚‰ã‚“ï¼ https://t.co/11YFRcdnAF']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "for tweet in tweets:\n",
    "    text = tweet\n",
    "    text = remove_emoji(text)\n",
    "    text = remove_url(text)\n",
    "    texts.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['å¹´å†…ã«3å€ä»¥ä¸Šï¼Ÿãƒ“ãƒƒãƒˆã‚³ã‚¤ãƒ³ã‚‚ã‚¤ãƒ¼ã‚µãƒªã‚¢ãƒ ã‚‚æ€¥é¨°ä¸­ï¼XRPæœ€æ–°æƒ…å ±ï¼†ç†±ã„ã‚ªãƒ«ãƒˆã‚³ã‚¤ãƒ³Chainlinkã¨FrontierãŒææºï¼Dogeã‚³ã‚¤ãƒ³ã®è¬ã®æ€¥æˆé•·ã¨NFTæœ€æ–°æƒ…å ±ï¼ï¼ˆå‹•ç”»ï¼‰â€¦ ',\n",
       " 'ã‚¤ãƒ¼ã‚µãƒªã‚¢ãƒ ãŒãƒˆãƒ¬ãƒ³ãƒ‰å…¥ã‚Šã—ã¦ã‚‹ã€‚\\nå¹´æœ«ã®ãƒ“ãƒƒãƒˆã‚³ã‚¤ãƒ³ã®ä¼¸ã³ã‚’é‘‘ã¿ã‚‹ã¨ã€3,400ãƒ‰ãƒ«ãŒã„ã£ãŸã‚“ã®ç¯€ç›®ã ã¨æ€ã£ã¦ã‚‹ã€‚\\n\\n#100ä¸‡è¡Œãã¾ã§å£²ã‚Šã¾ã›ã‚“\\n#ETH #ã‚¤ãƒ¼ã‚µãƒªã‚¢ãƒ ',\n",
       " 'ãƒ“ãƒƒãƒˆã‚³ã‚¤ãƒ³ã€è²·ã„ãŸã„æ°—æŒã¡ã€ç„¦ã‚‹æ°—æŒã¡ãŒå€¤æ®µãŒä¸ŠãŒã‚‹ã«ã¤ã‚Œã¦å‡ºã¦ãã‚‹ã‘ã©ã€æˆ‘æ…¢ãŒå¤§äº‹ã§ã™ã‚ˆã­',\n",
       " 'BAT ãƒ™ãƒ¼ã‚·ãƒƒã‚¯ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒˆãƒ¼ã‚¯ãƒ³ã¯\\nPoL @PoL_techtec ã®ã‚µã‚¤ãƒˆã§å­¦ã¹ã¾ã™ï¼\\n\\nä»®æƒ³é€šè²¨ã¯å€¤å‹•ãã®ä¸Šä¸‹ã ã‘ã§ã¯ãªãã€\\nä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹æŠ€è¡“ã«ã¤ã„ã¦è¦‹è­˜ã‚’æ·±ã‚ã‚‹ã®ã‚‚ã‚ˆãã§ã™ã­ï¼\\n\\nãƒ“ãƒƒãƒˆã‚³ã‚¤ãƒ³ ã‚„ ã‚¤ãƒ¼ã‚µãƒªã‚¢ãƒ ã‚‚Pâ€¦ ',\n",
       " '@UNOu3JaOmk4Tt9i ãƒ“ãƒƒãƒˆã‚³ã‚¤ãƒ³ï¼Ÿ',\n",
       " 'ãƒ“ãƒƒãƒˆã‚³ã‚¤ãƒ³ã®æœ€å¾Œã®åŠæ¸›æœŸå¾Œã£ã¦ã©ã†ãªã‚‹ã‚“ã§ã™ã‹ï¼Ÿ',\n",
       " 'ãƒ“ãƒƒãƒˆã‚³ã‚¤ãƒ³ã¾ãŸã‚ã¡ã‚ƒãã¡ã‚ƒå·»ãè¿”ã—ã¦ã‚‹ã­ã€‚1ä¸‡å††åˆ†ã ã‘ã—ã‹ãªã„ã‘ã©ã€ã›ã£ã‹ãã ã‹ã‚‰ä½•ãŒã‚ã£ã¦ã‚‚ç½®ã„ã¦ãŠã“ã†ã‹ãªâ€¦ã€‚',\n",
       " '@fuyuto_topics ã‚¦ã‚©ãƒ¬ãƒƒãƒˆã‚’å§‹ã‚ãŸé ƒãƒ“ãƒƒãƒˆã‚³ã‚¤ãƒ³ãŒã‚‚ã†é«˜ã‚ã ã£ãŸã®ã§ä½ã„ã‚¤ãƒ¼ã‚µãƒ ã«çµã‚Šã¾ã—ãŸã€‚\\nã“ã‚Œã‹ã‚‰ã‚‚ãƒã‚¤ãƒ³ãƒˆã¯ä¸‹ãŒã‚Œã°ãƒ“ãƒƒãƒˆã‚³ã‚¤ãƒ³ã¨ã‚¤ãƒ¼ã‚µãƒ ã‚’è²·ã„ç¶šã‘ã¾ã™ã€‚',\n",
       " 'ãƒ“ãƒƒãƒˆã‚³ã‚¤ãƒ³è²·ã£ã¦ã‚‹äººï¼\\nã©ã“ã®ã‚µã‚¤ãƒˆã§è²·ã£ã¦ã‚‹ï¼Ÿï¼Ÿ',\n",
       " 'çŸ­æœŸãƒˆãƒ¬ãƒ¼ãƒ‰ã®ã‚¤ãƒ¡ãƒ¼ã‚¸\\n\\næ±å¤§ã«è¡Œã‘ã‚‹äººãŒã„ã‚‹ã‚ˆã†ã«ã€å¯èƒ½æ€§ã¯å¦å®šã§ããªã„ã—\\nTwitterã«ã¯ãã‚Œä»¥ä¸Šã®è¶…äººãŒã„ã£ã±ã„ã‚‹ã€‚ãƒ“ãƒƒãƒˆã‚³ã‚¤ãƒ³ã¿ãŸã„ãªå¯èƒ½æ€§ã‚‚ã‚ã‚‹ã‚ã‘ã ã—ãªã€‚äººç”Ÿè‰¯ãã‚‚æ‚ªãã‚‚ä½•ãŒã‚ã‚‹ã‹åˆ†ã‹ã‚‰ã‚“ï¼ ']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from janome.tokenizer import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Tokenizer()\n",
    "worddic = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in texts:\n",
    "    malist = t.tokenize(line)\n",
    "    for w in malist:\n",
    "        word = w.surface\n",
    "        part = w.part_of_speech\n",
    "        if part.find('åè©') < 0:\n",
    "            continue\n",
    "        if not word in worddic:\n",
    "            worddic[word] = 0\n",
    "        worddic[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ã‚³ã‚¤ãƒ³(133)\n",
      "ãƒ“ãƒƒãƒˆ(127)\n",
      "#(45)\n",
      "å††(44)\n",
      "é€šè²¨(39)\n",
      "ä»®æƒ³(32)\n",
      "ä¸‡(22)\n",
      "ã‚¤ãƒ¼ã‚µãƒªã‚¢ãƒ (19)\n",
      ",(18)\n",
      "ã®(17)\n",
      "@(14)\n",
      "3(13)\n",
      "äºº(13)\n",
      ")(13)\n",
      "BTC(13)\n",
      "ã“ã¨(12)\n",
      "1(10)\n",
      "ã‚“(9)\n",
      "((9)\n",
      "æŠ•è³‡(9)\n",
      "ç™»éŒ²(9)\n",
      "/(9)\n",
      ".(9)\n",
      "ä¾¡æ ¼(9)\n",
      "åˆ†(8)\n",
      "å–å¼•(8)\n",
      "çš„(8)\n",
      "æ–¹(8)\n",
      "ä¸­(7)\n",
      "æš—å·(7)\n",
      "æ™‚(7)\n",
      ":(7)\n",
      "ç¾åœ¨(7)\n",
      "+(7)\n",
      "%(7)\n",
      "å£²è²·(7)\n",
      "ä»¥ä¸Š(6)\n",
      "ETH(6)\n",
      "_(6)\n",
      "ã‚µã‚¤ãƒˆ(6)\n",
      "ã¿ãŸã„(6)\n",
      "è³‡ç”£(6)\n",
      "ã¾ã¨ã‚(6)\n",
      "21(6)\n",
      "ç§(6)\n",
      "å¹´(6)\n",
      "å…¥é‡‘(6)\n",
      "è‡ªå‹•(6)\n",
      "000(6)\n",
      "å¾Œ(5)\n"
     ]
    }
   ],
   "source": [
    "trend_words = ''\n",
    "keys = sorted(worddic.items(), key=lambda x:x[1], reverse=True)\n",
    "for word, cnt in keys[:50]:\n",
    "    trend_words += word + ' '\n",
    "    print('{0}({1})'.format(word, cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_cloud(words, image_file, font_path='C:\\Windows/Fonts/MSGOTHIC.TTC'):\n",
    "    wordcloud = WordCloud(\n",
    "            background_color='white', font_path=font_path,   ## æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã‚’æŒ‡å®š\n",
    "            width=800, height=400).generate(words)\n",
    "\n",
    "    ## çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã¸ä¿å­˜\n",
    "    wordcloud.to_file(image_file)\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_cloud(trend_words, 'word_cloud_test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'search word: ãƒ“ãƒƒãƒˆã‚³ã‚¤ãƒ³\\nsearch tweets num: 10\\ntrend words num: 50'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_word = 'ãƒ“ãƒƒãƒˆã‚³ã‚¤ãƒ³'\n",
    "search_num = 10\n",
    "trend_word_num = 50\n",
    "tweet_text = 'search word: {}\\nsearch tweets num: {}\\ntrend words num: {}'.format(search_word, search_num, trend_word_num)\n",
    "tweet_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search word: ãƒ“ãƒƒãƒˆã‚³ã‚¤ãƒ³\n",
      "search tweets num: 10\n",
      "trend words num: 50\n"
     ]
    }
   ],
   "source": [
    "print(tweet_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media ID: 1389200235184877569\n",
      "tweet succeed!\n"
     ]
    }
   ],
   "source": [
    "tweet_image(oauth, tweet_text, 'word_cloud_test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
